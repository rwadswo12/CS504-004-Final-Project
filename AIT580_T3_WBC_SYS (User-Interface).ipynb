{"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import ipydeps\nipydeps.pip(['bs4', 'pandas','ipywidgets'])","metadata":{"ExecuteTime":{"end_time":"2021-10-11T13:53:35.026094Z","start_time":"2021-10-11T13:53:34.949747Z"}},"execution_count":null,"outputs":[],"id":"5374e16f"},{"cell_type":"code","source":"import ipywidgets as widgets\n\nimport pandas as pd\nimport pickle\nimport requests\n\nfrom bs4 import BeautifulSoup\nfrom ipywidgets import Layout\nfrom sklearn import preprocessing","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:09.575891Z","start_time":"2021-10-11T17:10:08.917253Z"},"trusted":true},"execution_count":1,"outputs":[],"id":"d24b3d48"},{"cell_type":"code","source":"# main fucntions","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:10.611154Z","start_time":"2021-10-11T17:10:10.608788Z"},"trusted":true},"execution_count":2,"outputs":[],"id":"ec20e124"},{"cell_type":"code","source":"def get_nfl_team_data(teams: dict, time_period: list) -> list:\n    # send requests to get data\n    data_list = []\n    index_cntr = 0\n    for team in teams:\n        for year in time_period:\n            url = f'https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/seasons/{year}/types/2/teams/{team[\"team_number\"]}/statistics'\n            try:\n                r_data = requests.get(url).json()['splits']['categories']\n\n                result ={'team': team['team_name']}\n                stat_list = []\n                for rec in r_data:\n                    stats_data = rec['stats']\n                    field_names, field_values = [] , []\n                    for stats_rec in stats_data:\n                        if stats_rec['name'].startswith(('passing','rushing', 'total')):\n                            if 'totalGiveaways' not in stats_rec['name'] or 'totalTakeaways' not in stats_rec['name']:\n                                stat_values = (stats_rec['name'], stats_rec['value'])\n                                stat_list.append(stat_values)\n\n                # convert to dataframe to get all values\n                df = pd.DataFrame(stat_list)\n\n                # transpose to get field values as columns\n                df = df.T\n                headers = df.iloc[0]\n                new_df  = pd.DataFrame(df.values[1:], columns=headers)\n                new_df = new_df.reset_index(drop=True)\n\n                # add team/year information\n                new_df['team_number'] = team['team_number']\n                new_df['team'] = team['team_name']\n                new_df['year'] = year\n                new_df['record_id'] = index_cntr\n                new_df = new_df.set_index('record_id')\n\n                # convert to dict\n                data_dict = new_df.to_dict(orient='records')\n                data_list.append(data_dict)\n                index_cntr += 1\n\n            except KeyError as err:\n                print(f'error with team: {team}, year: {year}')\n                # error will happen if data \n                # does not exist for a teams year\n                # skip past it for now\n                continue\n                \n    return data_list\n\n\ndef get_predictions(model, data, colnms):\n    \n    data = data.copy()\n    data = data[colnms]\n    \n    years = data['year'].values\n    teams = data['team'].values\n    \n    data_scaled = pd.DataFrame(preprocessing.scale(data[colnms].iloc[:, 0:12]),columns = data.columns[0:12]).copy()\n    data_scaled.loc[:,'team'] = data['team'].values\n    data_scaled.loc[:,'year'] = years\n    data_scaled = data_scaled.fillna(0)\n    \n    data_scaled.loc[:,'prediction'] = model.predict_proba(data_scaled.iloc[:,0:12].values)[:, 1]\n    data_year = data_scaled[['team','year','prediction']]\n    \n    display(data_year.sort_values(by=['prediction'], ascending=False))","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:11.293520Z","start_time":"2021-10-11T17:10:11.284898Z"},"trusted":true},"execution_count":3,"outputs":[],"id":"1cdc6d05"},{"cell_type":"markdown","source":"# Get data","metadata":{},"id":"841dec3d"},{"cell_type":"code","source":"print('Retrieving teams API map data')\nteams_url = 'https://raw.githubusercontent.com/bdbritt/gmu_ait580_nfl_project/master/teams.csv'\nteams = pd.read_csv(teams_url)\nprint(f'teams count: {teams.shape[0]}', '\\n')\n\nprint('Retrieving ML model testing data')\nml_test_data_url = 'https://raw.githubusercontent.com/bdbritt/gmu_ait580_nfl_project/master/nfl_historic_test_data.csv'\nml_test_data = pd.read_csv(ml_test_data_url)\nprint(f'historic stats data: {ml_test_data.shape[0]}', '\\n')\n\nprint('Retrieving 2021 team data. Please wait')\ntime_period = ['2021']\nresults = get_nfl_team_data(teams.to_dict('records'), time_period)\ncurrent_data = pd.concat([pd.DataFrame(rec) for rec in results]).reset_index(drop=True)\nprint(f'2021 stats data: {current_data.shape[0]}', '\\n')","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:25.111570Z","start_time":"2021-10-11T17:10:12.664231Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Retrieving teams API map data\nteams count: 32 \n\nRetrieving ML model testing data\nhistoric stats data: 121 \n\nRetrieving 2021 team data. Please wait\n","output_type":"stream"},{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n","output_type":"stream"},{"name":"stdout","text":"2021 stats data: 32 \n\n","output_type":"stream"}],"id":"174b3779"},{"cell_type":"code","source":"# Data Processing","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:12:01.464779Z","start_time":"2021-10-11T17:12:01.462882Z"},"trusted":true},"execution_count":5,"outputs":[],"id":"e91ac716"},{"cell_type":"code","source":"# combine current and test data\ncombined_data = pd.concat([ml_test_data, current_data]).copy()\n\nwanted_cols = ['totalYards', 'rushingYards', 'passingYardsAtCatch', \n               'totalOffensivePlays', 'passingFumblesLost', \n               'rushingFumblesLost', 'totalPenalties', \n               'totalTwoPointConvs', 'totalTackles', \n               'totalKickingPoints',  \n               'rushingBigPlays', \n               'passingBigPlays',\n               'team', 'year']\n\ncombined_data['year'] = combined_data['year'] = combined_data['year'].astype(int)\n\ncombined_data = combined_data[wanted_cols].copy()","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:38.657046Z","start_time":"2021-10-11T17:10:38.650558Z"},"trusted":true},"execution_count":6,"outputs":[],"id":"dd0089bd"},{"cell_type":"code","source":"ALL = 'ALL'\ndef unique_sorted_values_plus_ALL(array):\n    unique = array.unique().tolist()\n    unique.sort()\n    unique.insert(0, ALL)\n    return unique\n\ndropdown_state = widgets.Dropdown(options = unique_sorted_values_plus_ALL(combined_data[\"year\"]), description='Year: ')\n\noutput_predict = widgets.Output()\n\npca_cols = wanted_cols = ['totalYards', 'rushingYards', 'passingYardsAtCatch', \n               'totalOffensivePlays', 'passingFumblesLost', \n               'rushingFumblesLost', 'totalPenalties', \n               'totalTwoPointConvs', 'totalTackles', \n               'totalKickingPoints',  \n               'rushingBigPlays', \n               'passingBigPlays',\n               'team', 'year']\n\nmodel_url = 'https://raw.githubusercontent.com/bdbritt/gmu_ait580_nfl_project/master/logreg_model.pkl'\nlogreg = pd.read_pickle(model_url)\n\ndef event_action():\n    # clear the previous selection on each iteration\n    output_predict.clear_output()\n    \n    if (dropdown_state.value == ALL):\n        common_filter = combined_data\n        common_filter = common_filter[pca_cols].copy()\n    \n    else:\n        common_filter = combined_data.loc[combined_data['year']==dropdown_state.value]\n        \n        with output_predict:\n            get_predictions(logreg, common_filter, pca_cols)\n\n\ndef dropdown_state_eventhandler(change):\n    event_action()\n    \n\ndropdown_state.observe(dropdown_state_eventhandler, names='value')","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:39.408980Z","start_time":"2021-10-11T17:10:39.285737Z"},"trusted":true},"execution_count":7,"outputs":[],"id":"be925c0e"},{"cell_type":"code","source":"input_widgets = widgets.HBox([dropdown_state])\n\ntab = widgets.Tab([output_predict])\ntab.set_title(0, 'Prediction')\n\ndashboard = widgets.VBox([tab], layout=Layout(height='400px'))\ndisplay(input_widgets, dashboard)","metadata":{"ExecuteTime":{"end_time":"2021-10-11T17:10:45.522791Z","start_time":"2021-10-11T17:10:45.509063Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(Dropdown(description='Year: ', options=('ALL', 1996, 1997, 1998, 1999, 2021), value='ALL'),))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aeaf80d19a54b9ba84673881cac468f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Tab(children=(Output(),), _titles={'0': 'Prediction'}),), layout=Layout(height='400px'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58b519a2bd34adbbc3c62dccea386d5"}},"metadata":{}}],"id":"81e4ad91"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"5965239a-7652-49cf-b7af-dcdae5a80e29"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4ef1e960-5988-49d8-a5af-85f13cd043aa"}]}